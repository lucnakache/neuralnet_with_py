{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "## Machine Learning - Neural Network Learning\n",
    "\n",
    "import time\n",
    "start_time=time.time() \n",
    "\n",
    "from nnCostFunctionBackpropMat import *\n",
    "import numpy as np\n",
    "\n",
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "\n",
    "# we will use after parameters using : size_network=[400,25,10]\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "\n",
    "# Load Training Data\n",
    "print('Loading Data ...')\n",
    "\n",
    "# Loading directly features X et and target variable Y into \"base\" dictionary\n",
    "from scipy.io import loadmat\n",
    "base=loadmat(\"C:\\\\Users\\\\vincent\\\\Documents\\\\Big_data_and_Data_science\\\\Andrew_Ng\\\\Stanford-MachineLearning-exercises\\\\mlclass-ex4-007\\\\mlclass-ex4-007\\\\mlclass-ex4\\\\ex4data1.mat\")\n",
    "\n",
    "X=base['X']\n",
    "y=base['y']\n",
    "\n",
    "# We make minus 1 because we'll need to create \"one hot vectors\"\n",
    "y=y-1\n",
    "m=X.shape[0]\n",
    "\n",
    "## ============================== Part 2: Loading Parameters ================================================\n",
    "\n",
    "# Load of pre-initialized neural network parameters Theta1 and Theta2 into dictionaries theta1 and theta2\n",
    "theta=loadmat(\"C:\\\\Users\\\\vincent\\\\Documents\\\\Big_data_and_Data_science\\\\Andrew_Ng\\\\Stanford-MachineLearning-exercises\\\\mlclass-ex4-007\\\\mlclass-ex4-007\\\\mlclass-ex4\\\\ex4weights.mat\")\n",
    "theta1=theta['Theta1']\n",
    "theta2=theta['Theta2']\n",
    "\n",
    "# Total number of parameters of \"theta1\"\n",
    "length_theta1=hidden_layer_size*(input_layer_size+1)\n",
    "\n",
    "# After reshape, the 1st line comes in fisrt position in the vector\n",
    "# then comes the 2nd  line, the 3rd line, and so on ...\n",
    "theta1_reshape=theta1.reshape((1,length_theta1))[0]\n",
    "\n",
    "# Total number of parameters of \"theta2\"\n",
    "length_theta2=num_labels*(hidden_layer_size+1)\n",
    "theta2_reshape=theta2.reshape((1,length_theta2))[0]\n",
    "\n",
    "# Now unroll parameters : nn_params is a long vector\n",
    "nn_params = np.concatenate((theta1_reshape,theta2_reshape),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ================ Compute Cost (Feedforward) ================\n",
    "#  To the neural network, start by implementing the\n",
    "#  feedforward part of the neural network that returns the cost only.\n",
    " \n",
    "#  Implementing the feedforward cost *without* regularization\n",
    "#  After we will get the regularized cost.\n",
    "\n",
    "#print('Feedforward Using Neural Network ...')\n",
    "\n",
    "size_network = [400,25,10]\n",
    "length_theta = []\n",
    "# Il y n-1 matrices theta et z_value si n couches\n",
    "theta = []\n",
    "z_value = []\n",
    "\n",
    "regul = 0\n",
    "theta_grad = []\n",
    "delta = []\n",
    "\n",
    "# On affecte une valeur 0 pour commencer à l'indice 1\n",
    "# Bien noter que z[0] n'est pas utilisée pour les calculs\n",
    "\n",
    "#activations = []\n",
    "m=X.shape[0]\n",
    "# Pour le calcul matriciel de Back prop\n",
    "value_one_backprop=np.ones((m,1))\n",
    "# La 1ère colonne de X_with_one est bien une colonne de 1\n",
    "X_with_one = np.concatenate((np.ones((m,1)),X),axis=1)\n",
    "K = size_network[len(size_network)-1]\n",
    "value_one=np.array([1])\n",
    "\n",
    "# On initialise la matrice des données y observées avec \n",
    "y_i_backprop = np.zeros((m,K))\n",
    "for t in range(m):\n",
    "    y_i_backprop[t,y[t]]=1         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted values using forward_prop function\n",
    "pred = forward_prop(X_with_one,theta,value_one_backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight regularization parameter \n",
    "lambda_value=0\n",
    "J = cost(nn_params,m, pred[1], K,y,lambda_value,size_network)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta = init_theta(size_network,nn_params)[1]\n",
    "regul_terms(theta,size_network)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_prop(X_with_one,theta,value_one_backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =============== Regularization ===============\n",
    "# print('Checking Cost Function (Regularization) ... ')\n",
    "\n",
    "# Weight regularization parameter (we set this to 1 here).\n",
    "# lambda_value = 1\n",
    "\n",
    "# # NB : we set le 2nd index, is the max index of the \"activations[i]\" \n",
    "# # which are output of forward_prop function\n",
    "J = cost(nn_params,m,pred[1],K,y,lambda_value,size_network)\n",
    "\n",
    "# print(['Cost at parameters: %f (this value should be about 0.383770)'], J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_network = [400,25,10]\n",
    "\n",
    "# On initialise les longueurs des matrices theta dans dim_all\n",
    "# grace aux nombres de neurones par couche du réseau\n",
    "dim_all = []\n",
    "for i in range(len(size_network)-1):\n",
    "    dim_temp = size_network[i]+1, size_network[i+1]  \n",
    "    dim_all.append(dim_temp)\n",
    " \n",
    "# On affecte des valeurs aléatoirement dans les matrices theta\n",
    "theta = []\n",
    "length_theta = []\n",
    "for t in dim_all: \n",
    "    theta.append(np.random.randn(t[1],t[0]))\n",
    "    length_theta.append(t[0]*t[1])\n",
    "\n",
    "# Transformation des matrices theta en un vecteur long \"theta_params\"\n",
    "for i,t in zip(range(len(size_network)-1), theta):\n",
    "   if i==0:\n",
    "      theta_params = t.reshape((1,length_theta[i]))[0]\n",
    "   else:\n",
    "      theta_params = np.concatenate((theta_params,t.reshape((1,length_theta[i]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_value = forward_prop(X_with_one,theta,value_one_backprop)[0]\n",
    "# print (z_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = cost_fun(theta_params,args_1)\n",
    "theta = init_theta(size_network,theta_params)[1]\n",
    "\n",
    "z_value,activations = forward_prop(X_with_one,theta,value_one_backprop)\n",
    "\n",
    "args_1 = (m,activations,K,y,lambda_value,size_network)\n",
    "args_2 = (m,length_theta,size_network,activations,y_i_backprop,value_one_backprop,z_value,lambda_value,X_with_one)\n",
    "\n",
    "# On appliquera en faisant :\n",
    "# Gradient calculé avec backprop\n",
    "grad_check(cost_fun,theta_params,args_1,args_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 361.181818,
   "position": {
    "height": "384px",
    "left": "374.304px",
    "right": "20px",
    "top": "25.946px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
